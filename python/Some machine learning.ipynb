{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция возвращает список стихов с названиями\n",
    "def parse(text):\n",
    "    verse = ''\n",
    "    verses = []\n",
    "    for line in text:\n",
    "        if line.startswith('МЕТКА'):\n",
    "            continue\n",
    "        elif line.startswith('НАЗВАНИЕ'):\n",
    "            title = line.replace('НАЗВАНИЕ', '').strip()\n",
    "            if not title.isnumeric():\n",
    "                verse += title + '\\n\\n'\n",
    "        elif line == 'ТЕКСТ\\n':\n",
    "            continue\n",
    "        elif line == 'КОН\\n':\n",
    "            verses.append(verse)\n",
    "            verse = ''\n",
    "        else:\n",
    "            verse += line\n",
    "    \n",
    "    return verses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция преобразует список стихов в список списков токенов вида лемма_ЧАСТЬРЕЧИ\n",
    "# Классификация частей речи в формате Mystem\n",
    "# Возможен учёт стоп-слов\n",
    "def preprocess(texts, stop_words=None):\n",
    "    mystem = pymystem3.Mystem()\n",
    "    preprocessed_texts = []\n",
    "    \n",
    "    for text in texts:\n",
    "        preprocessed_text = []\n",
    "        analized = mystem.analyze(text)\n",
    "        \n",
    "        for result in analized:\n",
    "            if 'analysis' not in result:\n",
    "                continue\n",
    "            if result['analysis'] == []:\n",
    "                continue\n",
    "            lemma = result['analysis'][0]['lex']\n",
    "            if stop_words is not None:\n",
    "                if lemma in stop_words:\n",
    "                    continue\n",
    "            pos = result['analysis'][0]['gr'].split(',')[0].split('=')[0]\n",
    "            preprocessed_text.append(lemma.lower() + '_' + pos)\n",
    "            \n",
    "        preprocessed_texts.append(preprocessed_text)\n",
    "        \n",
    "    return preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаёт и возвращает обученную модель векторизованных токенов\n",
    "def create_model(preprocessed_texts, size=150, window=15, min_count=1, epochs=15):\n",
    "    model = gensim.models.Word2Vec(preprocessed_texts,\n",
    "                                   size=size, window=window, min_count=min_count)\n",
    "    model.train(preprocessed_texts, total_examples=model.corpus_count,\n",
    "                epochs=epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращает список текстов из texts, которые удовлетворяют запросу по слову word\n",
    "# topn - количество \"похожих\" слов, также используемых при поиске\n",
    "# log - показать список слов, использвуемых при поиске (слово + похожие)\n",
    "def search(word, model, texts, preprocessed_texts, topn=10, log=False):\n",
    "    mystem = pymystem3.Mystem()\n",
    "    analyzed = mystem.analyze(word)\n",
    "    try:\n",
    "        if 'analysis' not in analyzed[0]:\n",
    "            raise KeyError('Incorrect search queue')\n",
    "        if analyzed[0]['analysis'] == []:\n",
    "            raise KeyError('Incorrect word')\n",
    "        lemma = analyzed[0]['analysis'][0]['lex']\n",
    "        pos = analyzed[0]['analysis'][0]['gr'].split(',')[0].split('=')[0]\n",
    "        word = lemma + '_' + pos\n",
    "        if log:\n",
    "            print('Ищем: ' + word + ' ...')\n",
    "\n",
    "        searched_texts = set()\n",
    "        for i in range(len(preprocessed_texts)):\n",
    "            if word in preprocessed_texts[i]:\n",
    "                searched_texts.add(texts[i])\n",
    "        if topn > 0:\n",
    "            if log:\n",
    "                print('А также:')\n",
    "            for result in model.wv.most_similar(word, topn=topn):\n",
    "                similar_word = result[0]\n",
    "                if log:\n",
    "                    print(similar_word)\n",
    "                for i in range(len(preprocessed_texts)):\n",
    "                    if similar_word in preprocessed_texts[i]:\n",
    "                        searched_texts.add(texts[i])\n",
    "            if log:\n",
    "                print()\n",
    "        return list(searched_texts)\n",
    "    except KeyError:\n",
    "        return ['Поиск не дал результатов']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# При препроцессировании можно учесть стоп-слова, хотя заумь лучше оставить как есть\n",
    "f = open('stop_words.txt', 'r')\n",
    "stop_words = []\n",
    "for line in f:\n",
    "    stop_words.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель на сборнике Миши, не беря последние 3 стихотворения\n",
    "verses = parse(open('taskO1_sokolov.txt', 'r').readlines())[:-3]\n",
    "preprocessed_verses = preprocess(verses)\n",
    "model = create_model(preprocessed_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['что_SPRO',\n",
       " 'это_PART',\n",
       " 'так_ADVPRO',\n",
       " 'красный_A',\n",
       " 'рот_S',\n",
       " 'у_PR',\n",
       " 'жаба_S',\n",
       " 'не_PART',\n",
       " 'жевать_V',\n",
       " 'ль_PART']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Как выглядит словарь нашей модели\n",
    "list(model.wv.vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ищем: ко_PR ...\n",
      "А также:\n",
      "романюк_S\n",
      "анечка_S\n",
      "жека_S\n",
      "подушка_S\n",
      "комета_S\n",
      "кобзарь_S\n",
      "\n",
      "No one cares\n",
      "\n",
      "Кокетничая запонками\n",
      "из свеже-отравленных скорпионов\n",
      "Портовый кран\n",
      "вдвое вытянул\n",
      "изумрудный перископ головы\n",
      "и прикрыл\n",
      "индиговым сатином\n",
      "жабры,\n",
      "дразня пролетающих с Олимпа\n",
      "алебастровых богинь\n",
      "цин-ко-но-жек!..\n",
      "\n",
      "\n",
      "ОН\n",
      "\n",
      "кобзарь\n",
      "озарь\n",
      "грандиозарь\n",
      "виртуозарь\n",
      "\n",
      "\n",
      "Анечке Романюк\n",
      "\n",
      "ко ко\n",
      "ко ко ко\n",
      "ко ко\n",
      "ко ко ко\n",
      "ко ко\n",
      "ко ко ко\n",
      "ко\n",
      "ко\n",
      "ко ко\n",
      "ко ко ко\n",
      "ко\n",
      "ко ко ко\n",
      "ко\n",
      "ко ко ко\n",
      "ко\n",
      "ко ко ко\n",
      "ко ко\n",
      "ко ко\n",
      "ко ко\n",
      "ко ко\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "КОМЕТА ЗАБИЛАСЬ ко мне ПОД ПОДУШКУ\n",
      "Жужжит и щекочет, целуя колючее ушко\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "СМЕРТЬ ХУДОЖНИКА\n",
      "привыкнув ко всем безобразьям\n",
      "искал я их днем с фонарем\n",
      "но увы! все износились проказы\n",
      "не забыться мне ни на чем!\n",
      "и взор устремивши к бесплотным\n",
      "я тихо но твердо сказал:\n",
      "мир вовсе не рвотное —\n",
      "и мордой уткнулся в Обводный канал…\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Попробуем поискать знаменитое слово\n",
    "# Пока что поиск может искать только слова!\n",
    "for result in search('ко', model, verses, preprocessed_verses, topn=6, log=True):\n",
    "    print(result + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ищем: слизняк_S ...\n",
      "А также:\n",
      "Поиск не дал результатов\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Попробуем поискать слово, которое содержится в одном из последних трёх стихотворений\n",
    "for result in search('слизняк', model, verses, preprocessed_verses, log=True):\n",
    "    print(result + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дообучает модель новыми списками токенов\n",
    "def update_model(model, preprocessed_texts, epochs=15):\n",
    "    model.build_vocab(preprocessed_texts, update=True)\n",
    "    model.train(preprocessed_texts, total_examples=model.corpus_count,\n",
    "                epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дообучим нашу модель\n",
    "new_verses = parse(open('taskO1_sokolov.txt', 'r').readlines())[-3:]\n",
    "preprocessed_new_verses = preprocess(new_verses)\n",
    "update_model(model, preprocessed_new_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['что_SPRO',\n",
       " 'это_PART',\n",
       " 'так_ADVPRO',\n",
       " 'красный_A',\n",
       " 'рот_S',\n",
       " 'у_PR',\n",
       " 'жаба_S',\n",
       " 'не_PART',\n",
       " 'жевать_V',\n",
       " 'ль_PART']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим словарь\n",
    "list(model.wv.vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим, что новое слово теперь есть в словаре\n",
    "'слизняк_S' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ищем: слизняк_S ...\n",
      "А также:\n",
      "мой_APRO\n",
      "\n",
      "No one cares\n",
      "\n",
      "В полночь я заметил на всоей простыне черного и\n",
      "твердого,\n",
      "величиной с клопа\n",
      "в красной бахроме ножек.\n",
      "Прижег его спичкой. А он, потолстел без ожога, как\n",
      "повернутая дном железная бутылка…\n",
      "Я подумал: мало огня?…\n",
      "Но ведь для такого — спичка как бревно!…\n",
      "Пришедшие мои друзья набросали на него щепок,\n",
      "бумаги с керосином — и подожгли…\n",
      "Когда дым рассеялся — мы заметили зверька,\n",
      "сидящего в углу кровати\n",
      "в позе Будды (ростом с 1/4 аршина)\n",
      "И, как би-ба-бо ехидно улыбающегося.\n",
      "Поняв, что это ОСОБОЕ существо,\n",
      "я отправился за спиртом в аптеку\n",
      "а тем временем\n",
      "приятели ввертели ему окурками в живот\n",
      "пепельницу.\n",
      "Топтали каблуками, били по щекам, поджаривали уши,\n",
      "а кто-то накаливал спинку кровати на свечке.\n",
      "Вернувшись. я спросил:\n",
      "— Ну как?\n",
      "В темноте тихо ответили:\n",
      "— Все уже кончено!\n",
      "— Сожгли?\n",
      "— Нет, сам застрелился…\n",
      "ПОТОМУ ЧТО, сказал он,\n",
      "В ОГНЕ Я УЗНАЛ НЕЧТО ЛУЧШЕЕ!\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "Я прожарил свой мозг на железном пруте\n",
      "Добавляя перцу румян и кислот\n",
      "Чтобы он понравился, музка, тебе\n",
      "Больше, чем размазанный Игоря Северянина торт\n",
      "Чтобы ты вкушала щекоча ноготком\n",
      "Пахнущий терпентиом смочок.\n",
      "Сердце мое будет кувырком\n",
      "Как у нервного Кубелика\n",
      "Смычок\n",
      "\n",
      "\n",
      "стилистика кельи\n",
      "квартира корабль\n",
      "летящий\n",
      "во сне ноосферы\n",
      "зангези зау\n",
      "за у\n",
      "за уу\n",
      "крен вирус и визги\n",
      "скр ты\n",
      "скрыбыр ты\n",
      "удары словами поддых\n",
      "и не словами\n",
      "день-\n",
      "ги\n",
      "щипящее иго\n",
      "боль и больница\n",
      "реанимация\n",
      "мамочка мама не умирай\n",
      "папа держись\n",
      "мама и папа не уходите\n",
      "не уходите\n",
      "не уходите\n",
      "возьмите мои силы\n",
      "сан ра\n",
      "дети ра\n",
      "прана\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "Дым накрашенных\n",
      "ноздрей\n",
      "Курчавоглазого зверька\n",
      "Толчками сдул меня\n",
      "С площадки воздуха\n",
      "И я летел\n",
      "Как выроненный\n",
      "слизняк!..\n",
      "\n",
      "\n",
      "ны моя ны\n",
      "моя маленькая грязная ны\n",
      "моя нечистоплотная ны\n",
      "моя милая хорошая ны\n",
      "КРЕПКАЯ КАК ОРЕШЕК\n",
      "моя добрая старушка ны\n",
      "славная обкуренная трубка\n",
      "А КОГДА КУПИЛ НЕ ПОМНЮ\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "Слова мои — в охапку — многи —\n",
      "там перевязано пять друзей и купец!\n",
      "так не творил еще ни государь, ни Гоголь\n",
      "среди акаций пушАтых на железной дороге,\n",
      "Не одинок я и не лжец, —\n",
      "Крючек крученых молодец!…\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "Что это так красен рот у жабы?\n",
      "Не жевала ль эта жаба бетель?\n",
      "Пусть скорей приходит та, что хочет\n",
      "Моего отца женой стать милой!\n",
      "Мой отец ее приветно встретит,\n",
      "Рисом угостит и не ударит,\n",
      "Только мать моя глаза ей вырвет,\n",
      "Вырвет внутренности ей из брюха!\n",
      "\n",
      "\n",
      "МОЕ ТВОРЧЕСТВО\n",
      "\n",
      "ИЗ макушек оливы\n",
      "торчат дикобразы\n",
      "а в тяжелых огнях\n",
      "сидит напушка\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "жижа сквернословий\n",
      "мои крики самозваные\n",
      "не надо к ним предисловья\n",
      "— я хорош даже бранный!\n",
      "\n",
      "\n",
      "No one cares\n",
      "\n",
      "Чисто по женски нежно и ласково\n",
      "Она убеждает, что я талант\n",
      "Что меня по меню положат на — стол\n",
      "И будут все как лучший ужин захлебываясь лакать\n",
      "Ватага изысканных жевак\n",
      "Набросится на мою телячью ножку\n",
      "Кину им пачку улыбок золотых рыбок\n",
      "Будут пораженные плясать до утра бряцая воистину ложками\n",
      "Запивая ликером моей цветущей рубахи,\n",
      "Где на подтяжках висит красного дерева диван\n",
      "И стану в угол и буду от восхищение\n",
      "и благодарности плакать\n",
      "а за мною\n",
      "Весь кафе-ресторан…\n",
      "\n",
      "\n",
      "ТАТАРИН МОЙ татарин\n",
      "у тебя хорошие усы\n",
      "ТЫ СЛАВНО ЗАБИВАЕШЬ ГВОЗДИ\n",
      "прекрасный ты столяр\n",
      "ХОРОШИЙ ЧЕЛОВЕК ТАТАРИН\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Теперь он должен уметь искать новое слово и сам текст, в котором оно содержится\n",
    "for result in search('слизняк', model, verses + new_verses,\n",
    "                     preprocessed_verses + preprocessed_new_verses, topn=1, log=True):\n",
    "    print(result + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
